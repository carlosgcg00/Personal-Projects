{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnxV1dR0Zznm"
      },
      "source": [
        "# **Install dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RNHAFmgHZwUe",
        "outputId": "e7298ec2-a1f3-4ab0-e88f-43a5d40b3fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting googlemaps\n",
            "  Downloading googlemaps-4.10.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gmaps\n",
            "  Downloading gmaps-0.9.0.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openai\n",
            "  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting gmplot\n",
            "  Downloading gmplot-1.4.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Collecting jupyter_bokeh\n",
            "  Downloading jupyter_bokeh-4.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n",
            "  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from gmaps) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from gmaps) (7.7.1)\n",
            "Requirement already satisfied: traitlets>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gmaps) (5.7.1)\n",
            "Collecting geojson>=2.0.0 (from gmaps)\n",
            "  Downloading geojson-3.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gmaps) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter_bokeh) (3.4.3)\n",
            "Collecting ipywidgets>=7.0.0 (from gmaps)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter_bokeh) (1.3.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter_bokeh) (24.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter_bokeh) (2.1.4)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter_bokeh) (10.4.0)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter_bokeh) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter_bokeh) (2024.9.0)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=7.0.0->gmaps)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=7.0.0->gmaps)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->gmaps) (3.0.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->gmaps)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->gmaps) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->gmaps) (0.8.4)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh==3.*->jupyter_bokeh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh==3.*->jupyter_bokeh) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh==3.*->jupyter_bokeh) (2024.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->gmaps) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->gmaps) (0.2.13)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gmplot-1.4.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.7/164.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_bokeh-4.0.5-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading geojson-3.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: googlemaps, gmaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.10.0-py3-none-any.whl size=40716 sha256=eb68e29f09ed6a1994bfcaa5d96511a4a77c2c7e5f5b766922afa28bd8d9c6c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/f8/79/999d5d37118fd35d7219ef57933eb9d09886c4c4503a800f84\n",
            "  Building wheel for gmaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gmaps: filename=gmaps-0.9.0-py2.py3-none-any.whl size=2076086 sha256=8c32f504279b312750ba55726a329f22fc91e1ffa0ed826b6dd49a6fb7e96c0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/c2/dc/48b3ef16c2184dae51a003f17eb5d065bbbf1af3437d9f14e3\n",
            "Successfully built googlemaps gmaps\n",
            "Installing collected packages: widgetsnbextension, tenacity, python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, jedi, h11, geojson, comm, typing-inspect, jsonpatch, httpcore, googlemaps, gmplot, pydantic-settings, ipywidgets, httpx, dataclasses-json, openai, langsmith, jupyter_bokeh, gmaps, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.9\n",
            "    Uninstalling widgetsnbextension-3.6.9:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.9\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 dataclasses-json-0.6.7 geojson-3.1.0 gmaps-0.9.0 gmplot-1.4.1 googlemaps-4.10.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 ipywidgets-8.1.5 jedi-0.19.1 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 jupyter_bokeh-4.0.5 langchain-0.3.1 langchain-community-0.3.1 langchain-core-0.3.6 langchain-text-splitters-0.3.0 langsmith-0.1.129 marshmallow-3.22.0 mypy-extensions-1.0.0 openai-1.50.2 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 tenacity-8.5.0 typing-inspect-0.9.0 widgetsnbextension-4.0.13\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-community googlemaps gmaps openai gmplot python-dotenv torch jupyter_bokeh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grIBqK21DQUN",
        "outputId": "01644875-c705-45f2-fb52-6e4afa7e459a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=87718d1c1d935fd477a1d66db2c207b3a6fd0d7fbcf9d992a14469d0a9ffabc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "pip install langdetect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjzXDDmgaDlX"
      },
      "source": [
        "# Importación de GoogleMaps + OpenAI + HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "I1tVU7IcaDET"
      },
      "outputs": [],
      "source": [
        "OpenAI_Key = 'sk-'\n",
        "google_maps_API_Key = ''\n",
        "hugging_face_tk= 'hf_'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZ5ngY5aX9R"
      },
      "source": [
        "# **Routing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBuOSEiHB8aW"
      },
      "source": [
        "Include here all the necesary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qwiwqinNaBF9"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from langchain.agents import tool\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "import googlemaps\n",
        "import datetime\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDejlkWFB_oM"
      },
      "source": [
        "## **Langchain functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bG5FjxSrFbKL"
      },
      "outputs": [],
      "source": [
        "def find_place_return_address(google_maps_API_Key, input_text):\n",
        "\n",
        "    gmaps = googlemaps.Client(key=google_maps_API_Key)\n",
        "\n",
        "    result = gmaps.find_place(\n",
        "        input=input_text,\n",
        "        input_type='textquery',\n",
        "        fields=[\n",
        "            'formatted_address', 'geometry', 'types', 'place_id'\n",
        "        ],\n",
        "        language='es'\n",
        "    )\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1Omn6Bbcaojq"
      },
      "outputs": [],
      "source": [
        "# Define the GetCoordinates schema\n",
        "\n",
        "class GetCoordinatesInput(BaseModel):\n",
        "    place: str = Field(..., description=\"Place or address to get coordinates\")\n",
        "    google_api_key: str = Field(..., description=\"Google API Key\")\n",
        "\n",
        "@tool(args_schema=GetCoordinatesInput)\n",
        "def get_coordinates(place: str, google_api_key: str) -> dict:\n",
        "    \"\"\"Get the coordinates of an address\"\"\"\n",
        "    gmaps = googlemaps.Client(key=google_api_key)\n",
        "    # Hacer la solicitud geocoding, devuelve la latitude, longitude...\n",
        "    address = find_place_return_address(google_maps_API_Key, place)['candidates'][0]['formatted_address']\n",
        "    geocode_result = gmaps.geocode(address)\n",
        "\n",
        "    # Extraer las coordenadas (latitud y longitud)\n",
        "    location = geocode_result[0]['geometry']['location']\n",
        "    text_result = f'Address: {address} \\nLatitud: {location[\"lat\"]}, Longitud: {location[\"lng\"]}'\n",
        "    result = {'address': address,'location': location, 'text_result': text_result}\n",
        "    return {'location': location, 'text_result': text_result}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ofxl0hbPcYQ5"
      },
      "outputs": [],
      "source": [
        "# Define GetAddressFromCoordinates\n",
        "\n",
        "class GetAddressFromCoordinatesInput(BaseModel):\n",
        "    latitude: float = Field(..., description=\"Latitude\")\n",
        "    longitude: float = Field(..., description=\"Longitude\")\n",
        "    google_api_key: str = Field(..., description=\"Google API Key\")\n",
        "\n",
        "@tool(args_schema=GetAddressFromCoordinatesInput)\n",
        "def get_address_from_coordinates(latitude: float, longitude: float, google_api_key: str) -> dict:\n",
        "    \"\"\"Get the address from coordinates\"\"\"\n",
        "    gmaps = googlemaps.Client(key=google_api_key)\n",
        "    reverse_geocode_result = gmaps.reverse_geocode((latitude, longitude))\n",
        "\n",
        "    formated_address = reverse_geocode_result[0][\"formatted_address\"]\n",
        "    text_result = f'Latitud: {latitude}, Longitud: {longitude} \\nAddress: {formated_address}'\n",
        "    result = {'address': formated_address,'location': {'lat': latitude, 'lng': longitude}, 'text_result': text_result}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-95puZWPc0B0"
      },
      "outputs": [],
      "source": [
        "# Define GetDirections\n",
        "class GetDirectionsInput(BaseModel):\n",
        "    origin: str = Field(..., description=\"Origin place/address\")\n",
        "    destination: str = Field(..., description=\"Destination place/address\")\n",
        "    mode: Optional[str] = Field(None, description=\"Travel mode (driving, walking, bicycling, transit)\")\n",
        "    language: str = Field(None, description=\"Language code (e.g., 'es', 'en')\")\n",
        "    google_api_key: str = Field(..., description=\"Google API Key\")\n",
        "\n",
        "\n",
        "@tool(args_schema=GetDirectionsInput)\n",
        "def get_directions(origin: str, destination: str, google_api_key: str, mode: Optional[str] = 'driving',\n",
        "                   language: str = 'es') -> dict:\n",
        "    \"\"\"Get directions from origin to destination\"\"\"\n",
        "    # Initialize Google Maps client with the API key\n",
        "    gmaps = googlemaps.Client(key=google_api_key)\n",
        "\n",
        "    # Get the current date and time\n",
        "    now = datetime.datetime.now()\n",
        "\n",
        "    origin = find_place_return_address(google_maps_API_Key, origin)['candidates'][0]['formatted_address']\n",
        "    destination = find_place_return_address(google_maps_API_Key, destination)['candidates'][0]['formatted_address']\n",
        "\n",
        "    # Request directions between origin and destination\n",
        "    directions_result = gmaps.directions(\n",
        "        origin=origin,\n",
        "        destination=destination,\n",
        "        mode=mode,  # mode: [\"driving\", \"walking\", \"bicycling\", \"transit\"]\n",
        "        departure_time=now,\n",
        "        language=language,\n",
        "        traffic_model='best_guess'  # traffic_model: [\"best_guess\", \"optimistic\", \"pessimistic\"]\n",
        "    )\n",
        "\n",
        "    # Extract relevant information\n",
        "    if directions_result:\n",
        "        route = directions_result[0]['legs'][0]\n",
        "        distance_total = route['distance']['text']\n",
        "        duration_total = route['duration']['text']\n",
        "        steps = route['steps']\n",
        "        directions = ''\n",
        "\n",
        "        # Extract step-by-step instructions and distances\n",
        "        for i, step in enumerate(steps):\n",
        "            # Remove HTML tags from the instructions\n",
        "            instructions = step['html_instructions'].replace('<b>', '').replace('</b>', '').replace('<div style=\"font-size:0.9em\">', ' ').replace('</div>', '')\n",
        "            distance = step['distance']['text']\n",
        "            directions += f\"{i + 1}. {instructions} ({distance})\\n\"\n",
        "        result_txt = f'Origin: {origin}\\nDestination: {destination}\\nDuration: {duration_total}\\nDistance: {distance_total}\\nDirections:\\n{directions}'\n",
        "\n",
        "    else:\n",
        "        directions = None\n",
        "        distance_total = None\n",
        "        duration_total = None\n",
        "        result_txt = \"No directions in the route requested\"\n",
        "\n",
        "    result = {'origin addr': origin, 'destination addr': destination,\n",
        "              'duration': duration_total, 'distance_total': distance_total,\n",
        "              'directions': directions, 'text_result': result_txt}\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NVWiNyRWeAk1"
      },
      "outputs": [],
      "source": [
        "# Define GetPlacesNearby\n",
        "\n",
        "class GetPlacesNearbyInput(BaseModel):\n",
        "    address: str = Field(..., description=\"Address to get nearby places\")\n",
        "    radius: Optional[int] = Field(None, description=\"Radius in meters\")\n",
        "    keyword: Optional[str] = Field(None, description=\"Keyword to filter places\")\n",
        "    min_price: Optional[int] = Field(None, description=\"Minimum price level, 0: Free, 1: Inexpensive, 2: Moderate, 3: Expensive, 4: Very Expensive\")\n",
        "    max_price: Optional[int] = Field(None, description=\"Maximum price level, 0: Free, 1: Inexpensive, 2: Moderate, 3: Expensive, 4: Very Expensive\")\n",
        "    open_now: Optional[bool] = Field(None, description=\"Whether to include only places that are open now\")\n",
        "    rank_by: Optional[str] = Field(None, description=\"Ranking criteria, prominence or distance, if distance, radius canot be set\")\n",
        "    place_type: Optional[str] = Field(None, description=\"Type of the flace, e.g.: restaurant, cafe, park, museum...\")\n",
        "    language: str = Field(None, description=\"Language code (e.g., 'es', 'en')\")\n",
        "    limit_places: Optional[int] = Field(None, description=\"Number of places to return\")\n",
        "    google_api_key: str = Field(..., description=\"Google API Key\")\n",
        "\n",
        "@tool(args_schema=GetPlacesNearbyInput)\n",
        "def get_places_nearby(address: str, google_api_key: str, radius: Optional[int] = 5000, keyword: Optional[str] = None,\n",
        "                      min_price: Optional[int] = None, max_price: Optional[int] = None,\n",
        "                      open_now: Optional[bool] = None, rank_by: Optional[str] = 'prominence',\n",
        "                      place_type: Optional[str] = None, language: str = 'es', limit_places: Optional[int]=5) -> dict:\n",
        "    \"\"\"Get nearby places from an address\"\"\"\n",
        "    # Initialize Google Maps client\n",
        "    gmaps = googlemaps.Client(key=google_api_key)\n",
        "\n",
        "    # Get the location from the provided address\n",
        "    location = find_place_return_address(google_maps_API_Key, address)['candidates'][0]['geometry']['location']\n",
        "\n",
        "    # Set up the search parameters for places_nearby\n",
        "    search_params = {\n",
        "        'location': location,\n",
        "        'radius': radius,\n",
        "        'keyword': keyword,\n",
        "        'min_price': min_price,\n",
        "        'max_price': max_price,\n",
        "        'open_now': open_now,\n",
        "        'rank_by': rank_by,\n",
        "        'type': place_type,\n",
        "        'language': language\n",
        "    }\n",
        "\n",
        "    # Remove None values to avoid sending unnecessary parameters\n",
        "    search_params = {k: v for k, v in search_params.items() if v is not None}\n",
        "\n",
        "    # Search for places nearby using Google Maps API\n",
        "    places_result = gmaps.places_nearby(**search_params)\n",
        "\n",
        "    # Extract the relevant information\n",
        "    result_dict = {}\n",
        "    text_results = []\n",
        "\n",
        "    if places_result and 'results' in places_result:\n",
        "        places_result['results'] = places_result['results'][:limit_places]\n",
        "        for idx, place in enumerate(places_result['results']):\n",
        "            name = place.get('name', 'No name available')\n",
        "            address = place.get('vicinity', 'No address available')\n",
        "            rating = place.get('rating', 'No rating available')\n",
        "            number_reviews = place.get('user_ratings_total', 'No reviews available')\n",
        "            price = place.get('price_level', 'No price level available')\n",
        "            open_now_status = place.get('opening_hours', {}).get('open_now', 'No information available')\n",
        "            place_id = place.get('place_id', 'No place ID available')\n",
        "\n",
        "            # Prepare the dictionary for each place\n",
        "            place_data = {\n",
        "                'name': name,\n",
        "                'address': address,\n",
        "                'rating': rating,\n",
        "                'number_reviews': number_reviews,\n",
        "                'price_level': price,\n",
        "                'open_now': open_now_status,\n",
        "                'place_id': place_id\n",
        "            }\n",
        "\n",
        "            # Add a text summary for this place\n",
        "            text_summary = (\n",
        "                f\"Place #{idx+1}: {name}\\n\"\n",
        "                f\"  - Address: {address}\\n\"\n",
        "                f\"  - Rating: {rating}\\n\"\n",
        "                f\"  - Number of Reviews: {number_reviews}\\n\"\n",
        "                f\"  - Price Level: {price}\\n\"\n",
        "                f\"  - Open Now: {open_now_status}\\n\"\n",
        "                f\"  - Place ID: {place_id}\\n\"\n",
        "            )\n",
        "            text_results.append(text_summary)\n",
        "\n",
        "            # Add the place data to the result dictionary\n",
        "            result_dict[f'place_{idx+1}'] = place_data\n",
        "\n",
        "        # Add the textual result to the dictionary\n",
        "        result_dict['text_result'] = \"\\n\".join(text_results)\n",
        "    else:\n",
        "        result_dict['text_result'] = \"No places found for the given criteria.\"\n",
        "\n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dNS7pulAhtKm"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "from langchain.tools import tool\n",
        "import googlemaps\n",
        "\n",
        "# GetDetails\n",
        "class GetDetailsInput(BaseModel):\n",
        "    input_text: str = Field(..., description=\"Name or address of the place to get details\")\n",
        "    language: str = Field('es', description=\"Language code (e.g., 'es', 'en')\")\n",
        "    limit_reviews: Optional[int] = Field(5, description=\"Number of reviews to return\")\n",
        "    review_order: Optional[str] = Field(None, description=\"Order of the reviews: 'recent', 'high_rating', or 'low_rating'\")\n",
        "    google_api_key: str = Field(..., description=\"Google API Key\")\n",
        "\n",
        "@tool(args_schema=GetDetailsInput)\n",
        "def get_details(input_text: str, google_api_key: str, language: str = 'es',\n",
        "                review_order: Optional[str] = None, limit_reviews: Optional[int] = 5) -> dict:\n",
        "    \"\"\"Get details and reviews from a specific place.\"\"\"\n",
        "    # Initialize Google Maps client\n",
        "    gmaps = googlemaps.Client(key=google_api_key)\n",
        "\n",
        "    # Use find_place to search for the specific place\n",
        "    # find_place_result = gmaps.find_place(input=input_text, input_type='textquery', language=language, fields=['place_id'])\n",
        "\n",
        "    # if not find_place_result['candidates']:\n",
        "    #     return {\"error\": \"No se encontró ningún lugar con esa entrada.\"}\n",
        "\n",
        "    # place_id = find_place_result['candidates'][0]['place_id']\n",
        "    place_id = find_place_return_address(google_maps_API_Key, input_text=input_text)['candidates'][0]['place_id']\n",
        "    # Get detailed information for the selected place\n",
        "    details = gmaps.place(place_id=place_id, language=language)['result']\n",
        "    # Extract reviews\n",
        "    reviews = details.get('reviews', [])\n",
        "\n",
        "    # Sort reviews based on the review_order parameter\n",
        "    if review_order == 'recent':\n",
        "        # Sort by most recent\n",
        "        reviews = sorted(reviews, key=lambda x: x['time'], reverse=True)\n",
        "    elif review_order == 'high_rating':\n",
        "        # Sort by highest rating\n",
        "        reviews = sorted(reviews, key=lambda x: x['rating'], reverse=True)\n",
        "    elif review_order == 'low_rating':\n",
        "        # Sort by lowest rating\n",
        "        reviews = sorted(reviews, key=lambda x: x['rating'])\n",
        "\n",
        "    # Extract key details\n",
        "    result_dict = {\n",
        "        'name': details.get('name', 'No disponible'),\n",
        "        'address': details.get('formatted_address', 'No disponible'),\n",
        "        'phone_number': details.get('formatted_phone_number', 'No disponible'),\n",
        "        'website': details.get('website', 'No disponible'),\n",
        "        'rating': details.get('rating', 'No disponible'),\n",
        "        'total_reviews': details.get('user_ratings_total', 'No disponible'),\n",
        "        'opening_hours': details.get('opening_hours', {}).get('weekday_text', 'No disponible'),\n",
        "        'reviews': [\n",
        "            {\n",
        "                'author_name': review.get('author_name', 'Anónimo'),\n",
        "                'rating': review.get('rating', 'No disponible'),\n",
        "                'text': review.get('text', 'No hay texto de reseña'),\n",
        "                'relative_time': review.get('relative_time_description', 'No disponible')\n",
        "            }\n",
        "            for review in reviews[:limit_reviews]  # Limit to the specified number of reviews\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return result_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg16dfj6DKCF"
      },
      "source": [
        "We need to format the functions that are going to be given to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wl4QyuPfVLb",
        "outputId": "3d248262-914b-4257-8826-428dd0ce2b0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-c14649052bd6>:1: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
            "  functions = [format_tool_to_openai_function(t) for t in [get_coordinates, get_address_from_coordinates,\n"
          ]
        }
      ],
      "source": [
        "functions = [format_tool_to_openai_function(t) for t in [get_coordinates, get_address_from_coordinates,\n",
        "                                                         get_directions, get_places_nearby,\n",
        "                                                         get_details]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7k8m5bjDaKV"
      },
      "source": [
        "## **Load the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TaF-B00cSz5J"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect\n",
        "\n",
        "def detect_language(text):\n",
        "    return detect(text)  # Return 'es' for spanish, 'en' for english\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OC1wdXBHQOdx"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.agent import AgentFinish\n",
        "import json  # We import json to handle the conversion of the dictionary to a string\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=OpenAI_Key, temperature=0).bind(functions=functions, function_call=\"auto\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\" + f\"GoogleAPI_key: {google_maps_API_Key}\"),\n",
        "    (\"user\", \"{input}\"  f\"GoogleAPI_key: {google_maps_API_Key}\")\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57VG0rbtEk7Y"
      },
      "source": [
        "## **Routing part**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01P1of5gEoKU"
      },
      "source": [
        "The routing mechanism ensures that the model first determines which function to use and what parameters are required. After executing the appropriate function and obtaining the result, the model is invoked again to generate a response tailored to the original prompt, using the retrieved data. This two-step process ensures that the output is both accurate and adapted to the language and context of the user's initial request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ESzDVkaoEm6O"
      },
      "outputs": [],
      "source": [
        "def route(result, original_input):\n",
        "    # Detect the language of the original input\n",
        "    language = detect_language(original_input)\n",
        "\n",
        "    if isinstance(result, AgentFinish):\n",
        "        return result.return_values['output']\n",
        "    else:\n",
        "        tools = {\n",
        "            \"get_coordinates\": get_coordinates,\n",
        "            \"get_address_from_coordinates\": get_address_from_coordinates,\n",
        "            \"get_directions\": get_directions,\n",
        "            \"get_places_nearby\": get_places_nearby,\n",
        "            \"get_details\": get_details\n",
        "        }\n",
        "\n",
        "        # Execute the selected tool with the provided input\n",
        "        tool_output = tools[result.tool].run(result.tool_input)\n",
        "        # Convert the dictionary to a string in JSON format\n",
        "        tool_output_str = json.dumps(tool_output)\n",
        "\n",
        "        # Create a new prompt to generate a clear message in the correct language\n",
        "        prompt2 = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are a helpful assistant, and you will respond in the language you were spoken to.\"),\n",
        "            (\"user\", f\"Original question: {original_input}\\nObtained data:\\n{{input}}\\nProvide a clear response to the original question using the obtained data clearly in {language}.\")\n",
        "        ])\n",
        "\n",
        "        # Prepare the string with the new prompt\n",
        "        chain2 = prompt2 | model\n",
        "\n",
        "        # Invoke the chain with the tool output as input\n",
        "        assistant_response = chain2.invoke({\"input\": tool_output_str})\n",
        "\n",
        "        # Extract the assistant's message\n",
        "        if hasattr(assistant_response, 'content'):\n",
        "            return assistant_response.content\n",
        "        else:\n",
        "            return assistant_response  # In case 'content' is not available\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP8q4ezIFftF"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OMkzxQ8G2sx"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "92vtqKyhQY0X"
      },
      "outputs": [],
      "source": [
        "input_txt = \"Give me some details of the Retiro de Madrid\"\n",
        "# Preparamos la cadena principal, pasando el input original para mantener el contexto\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | (lambda result: route(result, input_txt))\n",
        "\n",
        "# Invocamos la cadena con la consulta del usuario\n",
        "result = chain.invoke({\"input\": input_txt})\n",
        "display(Markdown(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Vpa9Rx6GDhU"
      },
      "outputs": [],
      "source": [
        "input_txt = \"Give me some details of what people think of the Museo Reina Sofia de Madrid\"\n",
        "# Preparamos la cadena principal, pasando el input original para mantener el contexto\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | (lambda result: route(result, input_txt))\n",
        "\n",
        "# Invocamos la cadena con la consulta del usuario\n",
        "result = chain.invoke({\"input\": input_txt})\n",
        "display(Markdown(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7hlQ8zwARKwn"
      },
      "outputs": [],
      "source": [
        "input_txt = \"Can you recommend pasta restaurants near Plaza España in Madrid?\"\n",
        "\n",
        "# Preparamos la cadena principal, pasando el input original para mantener el contexto\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | (lambda result: route(result, input_txt))\n",
        "\n",
        "# Invocamos la cadena con la consulta del usuario\n",
        "result = chain.invoke({\"input\": input_txt})\n",
        "display(Markdown(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K1gzrB1IRBtE"
      },
      "outputs": [],
      "source": [
        "input_txt = \"Estoy perdido en la Plaza España de Madrid y quiero ir al intercambiador de Moncloa, cuales son las indicaciones para ir en metro\"\n",
        "\n",
        "\n",
        "# Preparamos la cadena principal, pasando el input original para mantener el contexto\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | (lambda result: route(result, input_txt))\n",
        "\n",
        "# Invocamos la cadena con la consulta del usuario\n",
        "result = chain.invoke({\"input\": input_txt})\n",
        "display(Markdown(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzsEXFzWVxLP"
      },
      "source": [
        "# **Model + agent_scratchpad**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eonnePCFJQ3Z"
      },
      "source": [
        "In LangChain, the agent_scratchpad is a placeholder used to track the ongoing process of decision-making and action-taking by the language model. It logs the intermediate steps, actions, and observations that occur as the agent interacts with external systems or APIs, such as Google Maps. This feature allows the agent to maintain context and \"remember\" what has already been done, what actions it has attempted, and how it should proceed based on the outcomes of previous steps. By including agent_scratchpad in the prompt, LangChain ensures that this log is updated in real-time as the conversation unfolds, keeping track of the agent’s reasoning and actions.\n",
        "\n",
        "The agent_scratchpad is especially useful in multi-step tasks where the model needs to interact with external tools, process responses, and make decisions over multiple turns. For example, when querying an API, the agent will record the query in the scratchpad, and once the response comes in, it will add that observation to the same log. This allows the model to reason based on the full history of the task, helping it decide what the next best action should be, making the conversation more dynamic and coherent over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X4s0GlMGVyEH"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import MessagesPlaceholder\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\" + f\"and you know the Google API Key: {google_maps_API_Key}\"),\n",
        "    (\"user\", \"{input}\" ),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")  # We are going to pass the action and the observation\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "cE7l1yFsWTrD"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=OpenAI_Key, temperature=0).bind(functions=functions, function_call=\"auto\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZAs8lwVAWBP3"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5WAsLvQKWiev"
      },
      "outputs": [],
      "source": [
        "result1 = chain.invoke({\"input\": \"Obtain the coordinates of the Bernabeu in Madrid\",\n",
        "                        \"agent_scratchpad\": []})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9MQvyf7sXIU-"
      },
      "outputs": [],
      "source": [
        "result1.tool_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8eT4zkMMWwEI"
      },
      "outputs": [],
      "source": [
        "observation = get_coordinates(result1.tool_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pHjDoKgbW7Cf"
      },
      "outputs": [],
      "source": [
        "type(result1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "y3pGtDY0XcwI"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.format_scratchpad import format_to_openai_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3Quz35mEXgEn"
      },
      "outputs": [],
      "source": [
        "format_to_openai_functions([(result1, observation),])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PtNdDcWhYR-N"
      },
      "outputs": [],
      "source": [
        "result2 = chain.invoke({\n",
        "    \"input\": \"Obtain the coordinates of the Bernabeu in Madrid\",\n",
        "    \"agent_scratchpad\": format_to_openai_functions([(result1, observation),])\n",
        "})\n",
        "result2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4dmKlfEK5Bq"
      },
      "source": [
        "The RunnablePassthrough.assign is being used here to assign a specific transformation to the agent_scratchpad. It takes the intermediate_steps from the input (x) and applies the function format_to_openai_functions to reformat these steps. This allows the agent to dynamically track and process multiple actions or function calls by reformatting the intermediate steps as the agent progresses through its tasks. Essentially, it ensures that the agent can handle multi-step processes by keeping track of its ongoing actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0dk5O79xYwy_"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "agent_chain = RunnablePassthrough.assign(\n",
        "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        ") | chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rIdlg97uY9cB"
      },
      "outputs": [],
      "source": [
        "def run_agent(user_input):\n",
        "    intermediate_steps = []\n",
        "    while True:\n",
        "        result = agent_chain.invoke({\n",
        "            \"input\": user_input,\n",
        "            \"intermediate_steps\": intermediate_steps\n",
        "        })\n",
        "        if isinstance(result, AgentFinish):\n",
        "            return result\n",
        "        tool = {\n",
        "            \"get_coordinates\": get_coordinates,\n",
        "            \"get_address_from_coordinates\": get_address_from_coordinates,\n",
        "            \"get_directions\": get_directions,\n",
        "            \"get_places_nearby\": get_places_nearby,\n",
        "            \"get_details\": get_details\n",
        "        }[result.tool]\n",
        "        observation = tool.run(result.tool_input)\n",
        "        intermediate_steps.append((result, observation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GxYinp3LZHJ4"
      },
      "outputs": [],
      "source": [
        "run_agent(\"Obtain the coordinates of the Bernabeu in Madrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obofz2NXLxAq"
      },
      "source": [
        "In the following example we can see that the model is calling two functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Osrr5ANTZP9c"
      },
      "outputs": [],
      "source": [
        "run_agent(\"Obtener las coordenadas y restaurantes cerca del Bernabeu en Madrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu-Fxx9YZl92",
        "outputId": "801d5f40-791e-4a4a-84cf-ca8eb10750b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': 'Hello! How can I assist you today?'}, log='Hello! How can I assist you today?')"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_agent('Hi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbDw9BFHL_Yn"
      },
      "source": [
        "With the following we can follow the steps of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QQX5s-nJaIQy"
      },
      "outputs": [],
      "source": [
        "tools = [get_coordinates, get_address_from_coordinates, get_directions, get_places_nearby, get_details]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gOvkvNM7Z5o2"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8HwhockDZ_Bw"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Obtain the coordinates of the Bernabeu in Madrid\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QsJU4Sjvah34"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Obtain the restaurants close to the Bernabeu in Madrid\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNFO-JNqMZhW"
      },
      "source": [
        "But this does not include memory that is why the model cannot remember the previous message. Lets see this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "teIjP0XUMh2_"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Obtain the restaurants close to the place I asked you before\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt-gQnCRI1-M"
      },
      "source": [
        "# Model + history = Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "4zE00zCxalS4"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\" + f\"Remember to use the Google API key when needed: {google_maps_API_Key}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0OTkpdXfa3-Q"
      },
      "outputs": [],
      "source": [
        "agent_chain = RunnablePassthrough.assign(\n",
        "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        ") | prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqkKUd1dbI6u",
        "outputId": "c2ea1892-1b73-44fa-c97b-200af95c87db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-64-4554adb1bf85>:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Bk8GvDdlbKMo"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "utaCEroRbPuS"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Obtain the coordinates of the Bernabeu in Madrid\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lG21BCaCbRno"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Can you recommend me some restaurants here?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7oTdv4aUbyd0"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"What people think about the first restaurant you recommend me?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "giKQO9V2NMsU"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Summarize\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL6aYoJgInFi"
      },
      "source": [
        "## Creating an **aesthetic Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "TnuhBEwrcofQ"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def create_your_own(query: str) -> str:\n",
        "    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n",
        "    print(type(query))\n",
        "    return query[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dy0YRJYGcowL"
      },
      "outputs": [],
      "source": [
        "tools = [get_coordinates, get_address_from_coordinates, get_directions, get_places_nearby, get_details, create_your_own]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fKRghR6kcraJ",
        "outputId": "ee7ad8d4-0f34-4f36-9811-82583ead5726"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.holoviews_exec.v0+json": "",
            "text/html": [
              "<div id='69f8fc89-e608-46f1-a77c-982c00f76a52'>\n",
              "  <div id=\"aad3388f-03d0-4c26-a258-b28e4dc56fc3\" data-root-id=\"69f8fc89-e608-46f1-a77c-982c00f76a52\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"df3f2f71-45b6-420b-89ef-c92ab31b46c0\":{\"version\":\"3.4.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"69f8fc89-e608-46f1-a77c-982c00f76a52\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"a607f2b8-673d-4757-b59d-0f9db5687707\",\"attributes\":{\"plot_id\":\"69f8fc89-e608-46f1-a77c-982c00f76a52\",\"comm_id\":\"f7a499a273954500aa0ba9486dc262ad\",\"client_comm_id\":\"c4ee9bf6d5094ffca404c8c3fcdb5ef3\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
              "  var render_items = [{\"docid\":\"df3f2f71-45b6-420b-89ef-c92ab31b46c0\",\"roots\":{\"69f8fc89-e608-46f1-a77c-982c00f76a52\":\"aad3388f-03d0-4c26-a258-b28e4dc56fc3\"},\"root_ids\":[\"69f8fc89-e608-46f1-a77c-982c00f76a52\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ]
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "69f8fc89-e608-46f1-a77c-982c00f76a52"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "import panel as pn\n",
        "import param\n",
        "\n",
        "class cbfs(param.Parameterized):\n",
        "\n",
        "    def __init__(self, tools, **params):\n",
        "        super(cbfs, self).__init__( **params)\n",
        "        self.panels = []\n",
        "        self.functions = [format_tool_to_openai_function(f) for f in tools]\n",
        "        self.model = ChatOpenAI(temperature=0, api_key = OpenAI_Key).bind(functions=self.functions)\n",
        "        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are helpful but sassy assistant\" + f\"Remember to use the GoogleAPI when needed: {google_maps_API_Key}\"),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"user\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "        self.chain = RunnablePassthrough.assign(\n",
        "            agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        "        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
        "        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
        "\n",
        "    def convchain(self, query):\n",
        "        if not query:\n",
        "            return\n",
        "        inp.value = ''\n",
        "        result = self.qa.invoke({\"input\": query})\n",
        "        self.answer = result['output']\n",
        "        self.panels.extend([\n",
        "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
        "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
        "        ])\n",
        "        return pn.WidgetBox(*self.panels, scroll=True)\n",
        "\n",
        "\n",
        "    def clr_history(self,count=0):\n",
        "        self.chat_history = []\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZUKWkF7CctZf"
      },
      "outputs": [],
      "source": [
        "cb = cbfs(tools)\n",
        "\n",
        "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
        "\n",
        "conversation = pn.bind(cb.convchain, inp)\n",
        "\n",
        "tab1 = pn.Column(\n",
        "    pn.Row(inp),\n",
        "    pn.layout.Divider(),\n",
        "    pn.panel(conversation,  loading_indicator=True, height=800, width = 1000),\n",
        "    pn.layout.Divider(),\n",
        ")\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n",
        "    pn.Tabs(('Conversation', tab1))\n",
        ")\n",
        "dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8an8jkgyHUO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KDejlkWFB_oM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
